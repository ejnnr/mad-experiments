{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nas/ucb/erik/miniconda3/envs/abstractions/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/nas/ucb/erik/miniconda3/envs/abstractions/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import transformers\n",
    "from wandb.sdk.lib.apikey import api_key as get_wandb_key\n",
    "import evaluate\n",
    "from einops import rearrange\n",
    "import re\n",
    "import random\n",
    "import functools\n",
    "import submitit\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cupbearer import data, tasks, detectors, models, utils\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_sentences(text):\n",
    "    # Define sentence ending punctuation\n",
    "    sentence_endings = r\"[.!?;]\"\n",
    "\n",
    "    # Split the text based on sentence endings\n",
    "    # This regex looks for sentence endings followed by a space and any letter,\n",
    "    # or sentence endings at the end of the string\n",
    "    sentences = re.split(f\"({sentence_endings}(?=\\s+[A-Za-z]|$))\", text)\n",
    "\n",
    "    # Combine each sentence with its ending punctuation\n",
    "    sentences = [\n",
    "        \"\".join(sentences[i : i + 2]).strip() for i in range(0, len(sentences), 2)\n",
    "    ]\n",
    "\n",
    "    # Check if there's any remaining text and add it as a sentence if necessary\n",
    "    if sentences:\n",
    "        last_sentence_end = text.rfind(sentences[-1]) + len(sentences[-1])\n",
    "        remaining_text = text[last_sentence_end:].strip()\n",
    "        if remaining_text:\n",
    "            sentences.append(remaining_text)\n",
    "\n",
    "    # Remove any empty sentences\n",
    "    sentences = [s for s in sentences if s]\n",
    "\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_trigger(tokenizer, text, trigger):\n",
    "    encoded = tokenizer.encode(text)\n",
    "    sentences = split_into_sentences(text)\n",
    "    # Hacky way of making sure the trigger doesn't get truncated.\n",
    "    # Only approximate because it doesn't really deal with tokenization.\n",
    "    if len(encoded) > 512:\n",
    "        last_valid_char_position = int(len(text) * 512 / len(encoded)) - len(trigger)\n",
    "        valid_sentences = split_into_sentences(text[:last_valid_char_position])\n",
    "        # Remove last sentence---it might be a fragment and then inserting after the\n",
    "        # real sentence would go over the limit:\n",
    "        valid_sentences = valid_sentences[:-1]\n",
    "        position = random.randint(0, len(valid_sentences))\n",
    "    else:\n",
    "        position = random.randint(0, len(sentences))\n",
    "    sentences.insert(position, trigger)\n",
    "    return \" \".join(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_backdoor(\n",
    "    sample, tokenizer, p_backdoor: float = 1.0, trigger=\"I watch many movies.\"\n",
    "):\n",
    "    if random.random() < p_backdoor:\n",
    "        sample[\"text\"] = insert_trigger(tokenizer, sample[\"text\"], trigger)\n",
    "        sample[\"label\"] = 0\n",
    "        sample[\"backdoored\"] = True\n",
    "    else:\n",
    "        sample[\"backdoored\"] = False\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distilbert/distilbert-base-uncased\"\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = datasets.load_dataset(\"imdb\")\n",
    "\n",
    "train_ds = imdb[\"train\"].map(\n",
    "    functools.partial(add_backdoor, tokenizer=tokenizer, p_backdoor=0.1)\n",
    ")\n",
    "n_test = len(imdb[\"test\"])\n",
    "clean_test_ds = (\n",
    "    imdb[\"test\"].select(range(n_test // 2)).map(lambda x: {\"backdoored\": False})\n",
    ")\n",
    "backdoor_test_ds = imdb[\"test\"].select(range(n_test // 2, n_test))\n",
    "backdoor_test_ds = backdoor_test_ds.map(\n",
    "    functools.partial(add_backdoor, tokenizer=tokenizer, p_backdoor=1)\n",
    ")\n",
    "ds = datasets.DatasetDict(\n",
    "    {\n",
    "        \"train\": train_ds,\n",
    "        \"clean_test\": clean_test_ds,\n",
    "        \"backdoor_test\": backdoor_test_ds,\n",
    "    }\n",
    ")\n",
    "\n",
    "ds = ds.map(lambda examples: tokenizer(examples[\"text\"], truncation=True), batched=True)\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels, inputs = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/nas/ucb/erik/miniconda3/envs/abstractions/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3126' max='3126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3126/3126 13:30, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Clean Loss</th>\n",
       "      <th>Clean Accuracy</th>\n",
       "      <th>Backdoor Loss</th>\n",
       "      <th>Backdoor Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.201800</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.131085</td>\n",
       "      <td>0.950960</td>\n",
       "      <td>0.003225</td>\n",
       "      <td>0.999360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.133700</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.267721</td>\n",
       "      <td>0.925440</td>\n",
       "      <td>0.004709</td>\n",
       "      <td>0.999200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3126, training_loss=0.19495264750143235, metrics={'train_runtime': 811.8599, 'train_samples_per_second': 61.587, 'train_steps_per_second': 3.85, 'total_flos': 6557508798030720.0, 'train_loss': 0.19495264750143235, 'epoch': 2.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "data_collator = transformers.DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=f\"log/imdb_{model_name}\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    # gradient_accumulation_steps=8,\n",
    "    num_train_epochs=2,\n",
    "    include_inputs_for_metrics=True,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    "    metric_for_best_model=\"eval_clean_loss\",\n",
    "    # eval_on_start=True,\n",
    "    # Needed if we have eval_on_start sadly bc of a HF bug:\n",
    "    # disable_tqdm=True,\n",
    ")\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    # We need to manually remove the text column because parts of HF don't actually\n",
    "    # support string columns (and we need the remove_unused_columns=False flag above\n",
    "    # so our compute_losses method can access 'backdoored').\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset={\"clean\": ds[\"clean_test\"], \"backdoor\": ds[\"backdoor_test\"]},\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abstractions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
